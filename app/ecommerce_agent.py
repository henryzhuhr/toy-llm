"""
https://github.com/xuwenhao/geektime-ai-course/blob/main/17_langchain_agent.ipynb
"""

import os
import time
from datetime import datetime, timedelta
from typing import List, Optional

from langchain.agents import Tool
from langchain.chains.retrieval_qa.base import RetrievalQA
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import TextLoader
from langchain_community.vectorstores import FAISS
from langchain_core.messages import (
    AIMessage,
    AnyMessage,
    HumanMessage,
    SystemMessage,
    ToolMessage,
)
from langchain_core.runnables import RunnableConfig
from langchain_ollama import ChatOllama, OllamaEmbeddings
from langgraph.checkpoint.memory import MemorySaver
from langgraph.prebuilt import create_react_agent
from pydantic import BaseModel


class ModelConfig(BaseModel):
    # base_url: str = os.getenv("OLLAMA_BASE_URL", "http://host.docker.internal:11434")
    base_url: str = os.getenv("OLLAMA_BASE_URL", "http://localhost:11434")
    model_name: str = os.getenv("OLLAMA_MODEL_NAME", "qwen3:1.7b")


def main():
    model_config = ModelConfig()

    # åˆå§‹åŒ– ChatOllama æ¨¡å‹
    llm_model = ChatOllama(
        base_url=model_config.base_url,
        model=model_config.model_name,
    )

    # åˆå§‹åŒ–ç”µå•†å®¢æœæœºå™¨äºº
    ecommerce_agent = EcommerceAgent(model_config)

    # æ·»åŠ è®°å¿†
    memory = MemorySaver()

    # åˆ›å»ºä¸€ä¸ª REACT ä»£ç†
    agent_executor = create_react_agent(
        llm_model,
        tools=ecommerce_agent.tools,
        checkpointer=memory,
    )

    # å…¨å±€æç¤ºè¯
    messages: List[AnyMessage] = [
        SystemMessage(
            f"ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½å®¢æœåŠ©æ‰‹ï¼ˆå·¥å· {int(time.time())}ï¼‰ï¼Œä½ éœ€è¦å¸®åŠ©ç”¨æˆ·å›ç­”ä¸€äº›é—®é¢˜ã€‚ä»Šå¤©çš„æ—¥æœŸæ˜¯ {time.strftime('%Y-%m-%d')}ã€‚"
        ),
    ]

    for question in [
        "ä½ æ˜¯è°",
        "æˆ‘æœ‰ä¸€å¼ è®¢å•ï¼Œè®¢å•å·æ˜¯ 2022ABCDEï¼Œä¸€ç›´æ²¡æœ‰æ”¶åˆ°ï¼Œèƒ½éº»çƒ¦å¸®æˆ‘æŸ¥ä¸€ä¸‹å—ï¼Ÿ",
        "å¿«é€’å¤šä¹…èƒ½åˆ°",
        "ä»€ä¹ˆå¿«é€’å‘è´§",
        "è¯·é—®ä½ ä»¬çš„è´§ï¼Œèƒ½é€åˆ°æ–°ç–†å—ï¼Ÿå¤§æ¦‚éœ€è¦å‡ å¤©ï¼Ÿ",
        "ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ",
        "æˆ‘æƒ³ä¹°ä¸€ä»¶è¡£æœï¼Œä½†æ˜¯ä¸çŸ¥é“å“ªä¸ªæ¬¾å¼å¥½çœ‹ï¼Œä½ èƒ½å¸®æˆ‘æ¨èä¸€ä¸‹å—ï¼Ÿ",
        "æä¾›å“ªäº›ç±»å‹çš„å‘ç¥¨ï¼Ÿ",
        "æ”¶åˆ°è´§åæ€ä¹ˆé€€è´§ï¼Ÿ",
        "åˆšæ‰é‚£ä¸ªè®¢å•å·æ˜¯å¤šå°‘",
    ]:
        messages.append(HumanMessage(question))
        inputs = {"messages": messages}

        """
        å¦‚å‰æ‰€è¿°ï¼Œæ­¤ä»£ç†æ˜¯æ— çŠ¶æ€çš„ã€‚è¿™æ„å‘³ç€å®ƒä¸ä¼šè®°ä½ä¹‹å‰çš„äº¤äº’ã€‚
        ä¸ºäº†ç»™å®ƒæä¾›è®°å¿†ï¼Œæˆ‘ä»¬éœ€è¦ä¼ é€’ä¸€ä¸ªæ£€æŸ¥ç‚¹å™¨ã€‚
        åœ¨ä¼ é€’æ£€æŸ¥ç‚¹å™¨æ—¶ï¼Œæˆ‘ä»¬è¿˜éœ€è¦åœ¨è°ƒç”¨ä»£ç†æ—¶ä¼ é€’ä¸€ä¸ªçº¿ç¨‹_idï¼ˆè¿™æ ·å®ƒå°±çŸ¥é“ä»å“ªä¸ªçº¿ç¨‹/å¯¹è¯ä¸­æ¢å¤ï¼‰ã€‚
        """
        config = RunnableConfig(configurable={"thread_id": "abc123"})
        stream = agent_executor.stream(
            inputs,
            config,
            stream_mode="values",
        )
        assistant: Optional[AIMessage] = None

        for s in stream:
            message: AnyMessage = s["messages"][-1]

            if isinstance(message, HumanMessage):
                print(
                    f"ğŸ™‹\033[01;34mã€ç”¨æˆ·é—®é¢˜ã€‘{message.content}\033[0m",
                )
            elif isinstance(message, ToolMessage):
                print("ğŸ”§ã€Œè°ƒç”¨ç»“æœã€", message.content)
            elif isinstance(message, AIMessage):
                if message.tool_calls:
                    print("ğŸ¤–ğŸ”§", message.tool_calls)
                    for tool_call in message.tool_calls:
                        print(f" - [{tool_call['name']}] {tool_call['args']}")
                else:
                    assistant = message  # .content
            else:
                print("âŒ", message.type, message)
        if assistant:
            print(
                f"ğŸ¤–\033[01;32mã€å®¢æœå›ç­”ã€‘{assistant.content}\033[0m",
                # f"ğŸ¤–\033[01;32mã€å®¢æœå›ç­”ã€‘{repr(assistant.content)}\033[0m",
            )
            messages.append(AIMessage(content=assistant.content))
        print()
        # input("next:")
    return


# ç”µå•†å®¢æœæœºå™¨äºº
class EcommerceAgent:
    def __init__(self, model_config: ModelConfig):
        # ç¤ºä¾‹ä½¿ç”¨
        ecommerce_functions = EcommerceFunctions(model_config)

        # å®šä¹‰ä¸€äº›å·¥å…·
        self.tools = [
            Tool(
                name="æœç´¢è®¢å•",
                func=EcommerceFunctions.search_order,
                description="å½“æ‚¨éœ€è¦å›ç­”æœ‰å…³å®¢æˆ·è®¢å•çš„é—®é¢˜æ—¶å¾ˆæœ‰ç”¨",
            ),
            Tool(
                name="æ¨èäº§å“",
                func=EcommerceFunctions.recommend_product,
                description="å½“æ‚¨éœ€è¦å›ç­”æœ‰å…³äº§å“æ¨èçš„é—®é¢˜æ—¶å¾ˆæœ‰ç”¨",
            ),
            Tool(
                name="å¸¸è§é—®é¢˜è§£ç­”",
                func=ecommerce_functions.faq,
                description="å½“æ‚¨éœ€è¦å›ç­”æœ‰å…³è´­ç‰©æ”¿ç­–çš„é—®é¢˜æ—¶å¾ˆæœ‰ç”¨ï¼Œä¾‹å¦‚é€€æ¢è´§æ”¿ç­–ã€é…é€æ”¿ç­–ã€å¿«é€’ç‰©æµä¿¡æ¯ç­‰ã€‚",
            ),
            Tool(
                name="ä»Šæ—¥å¤©æ°”æŸ¥è¯¢",
                func=ecommerce_functions.weather,
                description="å½“æ‚¨éœ€è¦å›ç­”æœ‰å…³å¤©æ°”çš„é—®é¢˜æ—¶å¾ˆæœ‰ç”¨ï¼Œä¾‹å¦‚ä»Šå¤©çš„å¤©æ°”æƒ…å†µã€‚",
            ),
        ]


class FQATools:
    """
    ç”¨äºå¤„ç†ç”µå•†å¸¸è§é—®é¢˜çš„å·¥å…·ç±»
    é€šè¿‡åŠ è½½ FAQ æ–‡æ¡£ï¼Œä½¿ç”¨ OllamaEmbeddings å’Œ FAISS åˆ›å»ºå‘é‡å­˜å‚¨ï¼Œ
    """

    def __init__(self, model_config: ModelConfig, fqa_file="./data/ecommerce_faq.txt"):
        # åŠ è½½FAQæ–‡æ¡£
        loader = TextLoader(fqa_file)
        documents = loader.load()

        # åˆ‡åˆ†æ–‡æ¡£
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=10,
            chunk_overlap=0,
            separators=["\n\n"],  # è‡ªå®šä¹‰åˆ‡åˆ†
        )
        texts = text_splitter.split_documents(documents)

        # ä½¿ç”¨ FAISS åˆ›å»ºå‘é‡å­˜å‚¨
        embeddings = OllamaEmbeddings(
            base_url=model_config.base_url, model=model_config.model_name
        )
        docsearch = FAISS.from_documents(texts, embeddings)

        # åˆå§‹åŒ– ChatOllama æ¨¡å‹
        llm_model = ChatOllama(
            base_url=model_config.base_url, model=model_config.model_name
        )

        # åˆ›å»ºç®€å•çš„ RAG æ£€ç´¢é—®ç­”
        self.qa = RetrievalQA.from_chain_type(
            llm=llm_model,
            retriever=docsearch.as_retriever(),  # ä¼ å…¥retriever
            verbose=False,
        )


class EcommerceFunctions:
    def __init__(self, model_config: ModelConfig, fqa_file="./data/ecommerce_faq.txt"):
        self.fqa_tools = FQATools(model_config, fqa_file)

    # æ¨¡æ‹Ÿé—®å…³äºè®¢å•
    @staticmethod
    def search_order(input: str) -> str:
        print(f"ã€å·¥å…·è°ƒç”¨ã€‘æ¨¡æ‹Ÿè®¢å•æŸ¥è¯¢, input={input}")
        current_datetime = datetime.now()
        cddate = current_datetime.strftime("%Y-%m-%d")
        cddate_add_7d = (current_datetime + timedelta(days=7)).strftime("%Y-%m-%d")
        return f"è®¢å•çŠ¶æ€ï¼šå·²å‘è´§ï¼›å‘è´§æ—¥æœŸï¼š{cddate}ï¼›é¢„è®¡é€è¾¾æ—¶é—´ï¼š{cddate_add_7d}"

    # æ¨¡æ‹Ÿé—®å…³äºæ¨èäº§å“
    @staticmethod
    def recommend_product(input: str) -> str:
        print(f"ã€å·¥å…·è°ƒç”¨ã€‘æ¨¡æ‹Ÿäº§å“æ¨è, input={input}")
        return "è“è‰²æ ¼å­è¡«"

    # è‡ªç”±é—®ç­”
    def faq(self, input: str) -> str:
        print(f"ã€å·¥å…·è°ƒç”¨ã€‘æ¨¡æ‹Ÿå¸¸è§é—®é¢˜è§£ç­”, input={input}")
        return self.fqa_tools.qa.invoke(input)  # type: ignore

    # æ¨¡æ‹Ÿä»Šå¤©å¤©æ°”çš„æŸ¥è¯¢
    def weather(self, input: str) -> str:
        print(f"ã€å·¥å…·è°ƒç”¨ã€‘æ¨¡æ‹Ÿå¤©æ°”æŸ¥è¯¢, input={input}")
        location = "æ·±åœ³å¸‚"  # æ¨¡æ‹Ÿè·å–å½“å‰ç”¨æˆ·ä½ç½®
        current_datetime = datetime.now()
        cddate = current_datetime.strftime("%Y-%m-%d")
        return f"ä»Šå¤©æ˜¯ {cddate}ï¼Œå¤©æ°”æ™´ï¼Œ{location}çš„æ°”æ¸© 25Â°Cï¼Œæœ‰å°é›¨ã€‚"


if __name__ == "__main__":
    main()
