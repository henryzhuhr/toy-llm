"""
https://github.com/datawhalechina/handy-ollama/blob/main/docs/C7/7.%20ä½¿ç”¨%20DeepSeek%20R1%20å’Œ%20Ollama%20å®ç°æœ¬åœ°%20RAG%20åº”ç”¨.md
"""
from typing import List
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import WebBaseLoader
from langchain_chroma import Chroma
from langchain_ollama import OllamaEmbeddings
from langchain_ollama import ChatOllama

from langchain_core.documents import Document
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough


RAG_TEMPLATE = """
æ‚¨æ˜¯é—®ç­”ä»»åŠ¡çš„åŠ©æ‰‹ã€‚ä½¿ç”¨ä»¥ä¸‹æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡æ¥å›ç­”é—®é¢˜ã€‚å¦‚æœæ‚¨ä¸çŸ¥é“ç­”æ¡ˆï¼Œåªéœ€è¯´ä¸çŸ¥é“ã€‚

<context>
{context}
</context>

å›ç­”ä»¥ä¸‹é—®é¢˜:

{question}"""


def main():
    print("Welcome to the Ollama Chatbot!")

    headers = {
        "User-Agent": "",
        "accept": "*/*",
        "Accept-Language": "zh-CN,zh;q=0.9",
        "Connection": "keep-alive",
        "Cookie": "",
        "Priority": "u=0, i",
    }
    loader = WebBaseLoader(
        web_path="https://zhuanlan.zhihu.com/p/22922535643",
        header_template=headers,
    )

    documents = loader.load()
    for doc in documents:
        # print("ğŸŸ¢", doc.page_content)
        print("ğŸŸ¢", doc.metadata)
        print("ğŸŸ¢ğŸ“–", doc.page_content)

    print()
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)
    all_splits = text_splitter.split_documents(documents)
    for doc in documents:
        # print("ğŸŸ¢", doc.page_content)
        print("ğŸŸ¡", doc.metadata)
        print("ğŸŸ¡ğŸ“–", doc.page_content)

    local_embeddings = OllamaEmbeddings(model="nomic-embed-text")

    vectorstore = Chroma.from_documents(
        documents=all_splits, embedding=local_embeddings
    )

    model = ChatOllama(
        model="qwen2.5:3b",
    )

    rag_prompt = ChatPromptTemplate.from_template(RAG_TEMPLATE)

    retriever = vectorstore.as_retriever()

    qa_chain = (
        {"context": retriever | format_docs, "question": RunnablePassthrough()}
        | rag_prompt
        | model
        | StrOutputParser()
    )

    questions = ["å°è¡Œæ˜Ÿçš„å±å®³", "å°è¡Œæ˜Ÿçš„ç›´å¾„æ˜¯å¤šå°‘", "å¦‚ä½•è¯„ä»·ç¾å›½çš„è¡Œä¸º"]
    for question in questions:
        answer = qa_chain.invoke(question)
        print("ğŸ¤–", answer)


# å°†ä¼ å…¥çš„æ–‡æ¡£è½¬æ¢æˆå­—ç¬¦ä¸²çš„å½¢å¼
def format_docs(docs: List[Document]) -> str:
    return "\n\n".join(doc.page_content for doc in docs)


if __name__ == "__main__":
    main()
